{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from schlichtanders.mymatplotlib import Centre\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, platform, sys\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__file__ = os.path.realpath('__file__')\n",
    "if platform.system() == \"Windows\":\n",
    "    from schlichtanders.myos import replace_unc\n",
    "    __file__ = replace_unc(__file__)\n",
    "__path__ = os.path.dirname(__file__)\n",
    "__parent__ = os.path.dirname(__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, Unicode, UnicodeText, String, PickleType, Float, Boolean\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.orm import sessionmaker, Session, create_session\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "import operator as op\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import heapq\n",
    "from copy import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "inf = float('inf')\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import experiment_models\n",
    "import experiment_util\n",
    "from schlichtanders.mycontextmanagers import ignored\n",
    "from schlichtanders.myobjects import Namespace, NestedNamespace\n",
    "from evaluation_util import get_modes\n",
    "import evaluation_util as eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano_models as tm\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import theano_models.probabilistic_models as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names = { # sorted by optimization type\n",
    "    \"ml\": ['baselinedet', 'baselinedetplus'],\n",
    "    \"annealing\": ['baseline', 'baselineplus', 'mixture',\n",
    "                  'planarflow', 'planarflowdet', 'radialflow', 'radialflowdet'],\n",
    "    # first trials do not seem to be successfull, furthermore this needs a lot of time, maybe later on\n",
    "    # \"ml_exp_average\": ['mixtureml', 'planarflowml', 'radialflowml'],\n",
    "}\n",
    "model_prefixes = reduce(op.add, model_names.values())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this approach seems to have problems with pickling\n",
    "all_data = []\n",
    "\n",
    "for f in gen_subfiles(\"toy_windows\", \"toy_linux\"):\n",
    "    engine = create_engine('sqlite:///' + f)\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    Hyper = Base.classes.hyper\n",
    "    session = Session(engine)\n",
    "    all_data += session.query(Hyper).all()  # filter if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiment_util' from '/home/stephan/GitProjects/theano_models/experiments/experiment1/experiment_util.pyc'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(experiment_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hyper = experiment_util.get_old_hyper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetnames = [\"boston\", \"concrete\", \"energy\", \"kin8nm\", \"powerplant\", \"winered\", \"yacht\"]\n",
    "datasetname = \"boston\"\n",
    "\n",
    "data, error_func = experiment_util.load_and_preprocess_data(datasetname)\n",
    "X, Z, VX, VZ, TX, TZ = data\n",
    "example_input = X[0]\n",
    "example_output = Z[0]\n",
    "output_transfer = \"softmax\" if datasetname == \"mnist\" else \"identity\"\n",
    "dataset_id = example_input, example_output, output_transfer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_results = eva.load_test_results(datasetname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect models and find best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation_util' from '/home/stephan/GitProjects/theano_models/experiments/experiment1/__file__'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Hyper' object has no attribute 'percent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/experiments/experiment1/__file__\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m best_hyper = eva.get_best_hyper([\"run_windows\"], Hyper, model_prefixes, test_suffix=[\"best_val_loss\", \"val_error_rate\"],\n\u001b[1;32m----> 2\u001b[1;33m                                key = lambda fn, p: datasetname in fn)\n\u001b[0m",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/experiments/experiment1/__file__\u001b[0m in \u001b[0;36mget_best_hyper\u001b[1;34m(folders, Hyper, model_prefixes, percentages, test_suffix, key)\u001b[0m\n\u001b[0;32m    283\u001b[0m                     \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                     \u001b[1;31m# find best fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                     \u001b[0mall_data_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_normflows\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpercent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mall_data_nn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                         \u001b[0mhyper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_data_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# only the very best is wanted to keep it simple and clean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Hyper' object has no attribute 'percent'"
     ]
    }
   ],
   "source": [
    "best_hyper = eva.get_best_hyper([\"run_windows\"], Hyper, model_prefixes, test_suffix=[\"best_val_loss\", \"val_error_rate\"],\n",
    "                               key = lambda fn, p: datasetname in fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "best_hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_hyper['best_val_loss']['baseline'][1][1].datasetname"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for hy in all_data:\n",
    "    n_normflow = getattr(hy, \"n_normflows\")\n",
    "    params = [getattr(hy, name+\"_best_parameters\") for name in model_prefixes]\n",
    "    lengths = [len(p) if p is not None else 0 for p in params]\n",
    "    print n_normflow, lengths"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for name in best_results['best_val_loss']:\n",
    "    for n in n_normflows:\n",
    "        entries = best_results['best_val_loss'][name][n][1]\n",
    "        for e in entries:\n",
    "            params = getattr(e, name+\"_best_parameters\")\n",
    "            print name, n, len(params) #, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from experiment_util import to_pandas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=to_pandas_dict(datasetname, best_hyper)).to_csv(os.path.join(__path__, \"boston_old_best_results.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save all best_hyper"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pandas_dict = None\n",
    "for dn in datasetnames:\n",
    "    n_best = 3\n",
    "    _best_hyper = eva.get_best_hyper([\"run_windows\"], Hyper, model_prefixes,\n",
    "                                    n_best=n_best, test_suffix=[\"best_val_loss\", \"val_error_rate\"],\n",
    "                                   key = lambda fn, p: dn in fn)\n",
    "    pandas_dict = to_pandas_dict(dn, _best_hyper, pandas_dict)\n",
    "    print len(pandas_dict['datasetname'])\n",
    "pd.DataFrame(data=pandas_dict).to_csv(os.path.join(__path__, \"all_best_results.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Results on Test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(eva)\n",
    "reload(experiment_models)\n",
    "reload(experiment_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for computing test results\n",
    "pm.RNG = NestedNamespace(tm.PooledRandomStreams(pool_size=int(1e8)), RandomStreams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = eva.compute_test_results(\n",
    "    best_hyper, lambda hyper: experiment_util.load_and_preprocess_data(hyper.datasetname),\n",
    "    model_module_id=dataset_id, n_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results = eva.load_test_results(datasetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def last_layer_to_dict(l):\n",
    "    l[\"test_error_rate\"][np.isinf(l[\"test_error_rate\"])] = np.nan\n",
    "    l['best_test_loss'][np.isinf(l['best_test_loss'])] = np.nan\n",
    "    idx_nan = np.isnan(l[\"test_error_rate\"]) | np.isnan(l['best_test_loss'])\n",
    "    valid_epochs = l['best_epoch'][~ idx_nan]  # take out all unsuccessful trials\n",
    "    print valid_epochs, valid_epochs.std()\n",
    "    try:\n",
    "        d = {\"test_error_mean%i\"%i: np.nanmean(l[\"test_error_rate\"]),\n",
    "             \"test_nans%i\"%i: idx_nan.mean(),\n",
    "            \"test_error_std%i\"%i: np.nanstd(l[\"test_error_rate\"]),\n",
    "            \"test_loss_mean%i\"%i: np.nanmean(l['best_test_loss']),\n",
    "            \"test_loss_std%i\"%i: np.nanstd(l['best_test_loss']),\n",
    "            \"epochs_mean%i\"%i: valid_epochs.mean(),\n",
    "            \"epochs_std%i\"%i: valid_epochs.std()}\n",
    "    except Exception:\n",
    "        d = {\"test_error_mean%i\"%i: None,\n",
    "             \"test_nans%i\"%i: None,\n",
    "            \"test_error_std%i\"%i: None,\n",
    "            \"test_loss_mean%i\"%i: None,\n",
    "            \"test_loss_std%i\"%i: None,\n",
    "            \"epochs_mean%i\"%i: None,\n",
    "            \"epochs_std%i\"%i: None}\n",
    "    return d\n",
    "        \n",
    "test_results_pd = pd.DataFrame(\n",
    "    data=to_pandas_dict(datasetname, test_results, last_layer_to_dict=last_layer_to_dict))\n",
    "test_results_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample the approximate posterior distribution for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_with_index = test_results_pd.set_index([\"model\", \"datasetname\", \"n_normflows\"])\n",
    "pd_with_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_results_pd.set_index([\"model\", \"n_normflows\", \"datasetname\"]).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_hyper_samples = eva.sample_best_hyper(best_hyper, model_module_id=dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best_hyper_samples only refers to hypers which distribution can be compared (i.e. baselinedet and such is removed)\n",
    "test_attrs = sorted(best_hyper_samples.keys())\n",
    "model_prefixes = sorted(best_hyper_samples[test_attrs[0]].keys())\n",
    "n_normflows = sorted(best_hyper_samples[test_attrs[0]][model_prefixes[0]].keys())\n",
    "\n",
    "lp = len(model_prefixes)\n",
    "lnn = len(n_normflows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of modes / histogram of modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_modes = eva.get_nr_modes(best_hyper_samples, threshold_d=50)\n",
    "nr_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_modes = eva.get_nr_modes(best_hyper_samples)\n",
    "nr_modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations = eva.get_best_correlations(best_hyper_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_hyper['best_val_loss']['planarflow'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vmax(acc, a):\n",
    "    return max(acc, a.max())\n",
    "def vmin(acc, a):\n",
    "    return min(acc, a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations0 = fmap_results(lambda x: abs(x[0]), correlations)\n",
    "correlations0_vmax = -inf\n",
    "correlations0_vmin = inf\n",
    "correlations0_vmax = reduce_results(vmax, correlations0, correlations0_vmax)\n",
    "correlations0_vmin = reduce_results(vmin, correlations0, correlations0_vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_normflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only correlations from best one\n",
    "for test in test_attrs:\n",
    "    fig, axs = plt.subplots(ncols=len(n_normflows), nrows=len(model_prefixes), sharex=True, sharey=True)\n",
    "    axs_iter = axs.flat\n",
    "    for name in model_prefixes:\n",
    "        for nn in n_normflows:\n",
    "            ax = next(axs_iter)\n",
    "            ax.grid(False)\n",
    "            ax.axis(\"off\")\n",
    "            try:\n",
    "                im = ax.imshow(correlations0[test][name][nn],\n",
    "                               vmax=correlations0_vmax, vmin=correlations0_vmin, cmap=plt.cm.hot) #, norm=Centre()\n",
    "            except KeyError:  # radialflow has some problems\n",
    "                pass\n",
    "            \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "#     fig.tight_layout()\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative plots for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations1 = fmap_results(lambda x: abs(x[1]), correlations)\n",
    "correlations1_vmax = -inf\n",
    "correlations1_vmin = inf\n",
    "correlations1_vmax = reduce_results(vmax, correlations1, correlations1_vmax)\n",
    "correlations1_vmin = reduce_results(vmin, correlations1, correlations1_vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only correlations from best one\n",
    "for test in test_attrs:\n",
    "    fig, axs = plt.subplots(ncols=len(n_normflows), nrows=len(model_prefixes), sharex=True, sharey=True)\n",
    "    axs_iter = axs.flat\n",
    "    for name in model_prefixes:\n",
    "        for nn in n_normflows:\n",
    "            ax = next(axs_iter)\n",
    "            ax.grid(False)\n",
    "            ax.axis(\"off\")\n",
    "            try:\n",
    "                im = ax.imshow(correlations1[test][name][nn],\n",
    "                               vmax=correlations1_vmax, vmin=correlations1_vmin, cmap=plt.cm.hot) #, norm=Centre()\n",
    "            except KeyError:  # radialflow has some problems\n",
    "                pass\n",
    "            \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "#     fig.tight_layout()\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlations_ = fmap_results(lambda x: abs(np.array(x)), correlations)\n",
    "means = fmap_results(lambda x: x.mean(axis=0), correlations_)\n",
    "variances = fmap_results(lambda x: x.var(axis=0), correlations_)\n",
    "means_vmax = -inf\n",
    "means_vmin = inf\n",
    "variances_vmax = -inf\n",
    "variances_vmin = 0\n",
    "\n",
    "variances_vmax = reduce_results(vmax, variances, variances_vmax)\n",
    "variances_vmin = reduce_results(vmin, variances, variances_vmin)\n",
    "means_vmax = reduce_results(vmax, means, means_vmax)\n",
    "means_vmin = reduce_results(vmin, means, means_vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean\n",
    "for test in test_attrs:\n",
    "    fig, axs = plt.subplots(ncols=len(n_normflows), nrows=len(model_prefixes), sharex=True, sharey=True)\n",
    "    axs_iter = axs.flat\n",
    "    for name in model_prefixes:\n",
    "        for nn in n_normflows:\n",
    "            ax = next(axs_iter)\n",
    "            ax.grid(False)\n",
    "            ax.axis(\"off\")\n",
    "            try:\n",
    "                im = ax.imshow(means[test][name][nn],\n",
    "                               vmax=means_vmax, vmin=means_vmin, cmap=plt.cm.hot) #, norm=Centre()\n",
    "            except KeyError:  # radialflow has some problems\n",
    "                pass\n",
    "            \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "#     fig.tight_layout()\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variances\n",
    "for test in test_attrs:\n",
    "    fig, axs = plt.subplots(ncols=len(n_normflows), nrows=len(model_prefixes), sharex=True, sharey=True)\n",
    "    axs_iter = axs.flat\n",
    "    for name in model_prefixes:\n",
    "        for nn in n_normflows:\n",
    "            ax = next(axs_iter)\n",
    "            ax.grid(False)\n",
    "            ax.axis(\"off\")\n",
    "            try:\n",
    "                im = ax.imshow(variances[test][name][nn],\n",
    "                               vmax=variances_vmax, vmin=variances_vmin, cmap=plt.cm.hot)\n",
    "            except KeyError:  # radialflow has some problems\n",
    "                pass\n",
    "            \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "#     fig.tight_layout()\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": true
  },
  "toc_position": {
   "left": "1452.64px",
   "right": "20px",
   "top": "95.9653px",
   "width": "300px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
