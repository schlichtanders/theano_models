{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import contextlib\n",
    "import os, platform, sys, traceback\n",
    "from pprint import pformat, pprint\n",
    "import numpy as np\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "import random\n",
    "\n",
    "from schlichtanders.mycontextmanagers import ignored\n",
    "\n",
    "inf = float(\"inf\")\n",
    "\n",
    "from schlichtanders.myfunctools import compose, meanmap, summap, compose_fmap, Average\n",
    "from schlichtanders.mygenerators import eatN, chunk, chunk_list, every, takeN\n",
    "from schlichtanders.myobjects import NestedNamespace, Namespace\n",
    "\n",
    "import theano_models as tm\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "from theano_models import data\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import theano\n",
    "\n",
    "from sqlalchemy import Column, Integer, Unicode, UnicodeText, String, PickleType, Float, Boolean\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from copy import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "tm.inputting_references.update(['to_be_randomized'])\n",
    "tm.inputting_references, tm.outputting_references\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "pm.RNG = NestedNamespace(tm.PooledRandomStreams(pool_size=int(5e8)), RandomStreams())\n",
    "\n",
    "__file__ = os.path.realpath('__file__')\n",
    "if platform.system() == \"Windows\":\n",
    "    from schlichtanders.myos import replace_unc\n",
    "    __file__ = replace_unc(__file__)\n",
    "__path__ = os.path.dirname(__file__)\n",
    "__parent__ = os.path.dirname(__path__)\n",
    "\n",
    "suffix = \"\"\n",
    "datasetname = \"boston\"\n",
    "\n",
    "class Track(object):\n",
    "    def __getattr__(self, item):\n",
    "        return tm.track_model(getattr(tm, item))\n",
    "track = Track()\n",
    "\n",
    "# # Data\n",
    "#     # datasetnames = [\"boston\", \"concrete\", \"energy\", \"kin8nm\", \"naval\", \"powerplant\", \"protein\", \"winered\", \"yacht\", \"year\"]\n",
    "#     datasetnames = [\"boston\", \"concrete\", \"energy\", \"kin8nm\", \"naval\", \"powerplant\", \"winered\", \"yacht\"]\n",
    "# datasetname = \"concrete\"\n",
    "\n",
    "# TODO check planar flows, they don't work as expected... however radial flows work.. it is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z, X = getattr(data, \"_\" + datasetname)()\n",
    "# normalization is standard in Probabilistic Backpropagation Paper\n",
    "X_mean = X.mean(0)\n",
    "X_std = X.std(0)\n",
    "X = (X - X_mean) / X_std\n",
    "Z_mean = Z.mean(0)\n",
    "Z_std = Z.std(0)\n",
    "Z = (Z - Z_mean) / Z_std\n",
    "\n",
    "X, TX, Z, TZ = cross_validation.train_test_split(X, Z, test_size=0.1) # 10% test used in paper\n",
    "X, VX, Z, VZ = cross_validation.train_test_split(X, Z, test_size=0.1) # 20% validation used in paper\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def log_exceptions(title, *exceptions):\n",
    "    if not exceptions:\n",
    "        exceptions = Exception\n",
    "    try:\n",
    "        yield\n",
    "    except exceptions:\n",
    "        with open(os.path.join(__path__, 'experiment%s_errors.txt' % suffix), \"a\") as myfile:\n",
    "            error = \"\"\"\n",
    "%s\n",
    "------------\n",
    "LAST HYPER: %s\n",
    "ORIGINAL ERROR: %s\"\"\" % (title, pformat(hyper.__dict__), traceback.format_exc())\n",
    "            myfile.write(error)\n",
    "\n",
    "\n",
    "def RMSE(PX, Z):\n",
    "    return np.sqrt(((PX - Z) ** 2).mean())\n",
    "\n",
    "def nRMSE(PX, Z):\n",
    "    return RMSE(PX*Z_std + Z_mean, Z*Z_std + Z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "\n",
    "engine = create_engine('sqlite:///' + os.path.join(__path__, 'test%s.db' % suffix))\n",
    "Base = declarative_base(bind=engine)\n",
    "\n",
    "class RandomHyper(Base):\n",
    "    __tablename__ = \"hyper\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "\n",
    "\n",
    "    # hyper parameters:\n",
    "    datasetname = Column(String)\n",
    "    max_epochs_without_improvement = Column(Integer)\n",
    "    logP_average_n = Column(Integer)\n",
    "    errorrate_average_n = Column(Integer)\n",
    "    units_per_layer = Column(Integer)\n",
    "    minus_log_s = Column(Integer)\n",
    "    batch_size = Column(Integer)\n",
    "    \n",
    "    n_normflows = Column(Integer)\n",
    "    \n",
    "    opt_identifier = Column(String)\n",
    "    opt_momentum = Column(Float)\n",
    "    opt_offset = Column(Float)\n",
    "    opt_decay = Column(Float)\n",
    "    opt_step_rate = Column(Float)\n",
    "\n",
    "    # baseline:\n",
    "    baseline_best_val_loss = Column(Float)\n",
    "    baseline_best_parameters = Column(PickleType, nullable=True)\n",
    "    baseline_train_loss = Column(PickleType)\n",
    "    baseline_val_loss = Column(PickleType)\n",
    "    baseline_epochs = Column(Integer)\n",
    "    baseline_init_params = Column(PickleType, nullable=True)\n",
    "    baseline_val_error_rate = Column(Float)\n",
    "\n",
    "    # planarflow:\n",
    "    planarflow_best_val_loss = Column(Float)\n",
    "    planarflow_best_parameters = Column(PickleType, nullable=True)\n",
    "    planarflow_train_loss = Column(PickleType)\n",
    "    planarflow_val_loss = Column(PickleType)\n",
    "    planarflow_epochs = Column(Integer)\n",
    "    planarflow_init_params = Column(PickleType, nullable=True)\n",
    "    planarflow_val_error_rate = Column(Float)\n",
    "\n",
    "    # planarflow deterministic:\n",
    "    planarflowdet_best_val_loss = Column(Float)\n",
    "    planarflowdet_best_parameters = Column(PickleType, nullable=True)\n",
    "    planarflowdet_train_loss = Column(PickleType)\n",
    "    planarflowdet_val_loss = Column(PickleType)\n",
    "    planarflowdet_epochs = Column(Integer)\n",
    "    planarflowdet_init_params = Column(PickleType, nullable=True)\n",
    "    planarflowdet_val_error_rate = Column(Float)\n",
    "\n",
    "    # planarflow maximum likelihood:\n",
    "    planarflowml_best_val_loss = Column(Float)\n",
    "    planarflowml_best_parameters = Column(PickleType, nullable=True)\n",
    "    planarflowml_train_loss = Column(PickleType)\n",
    "    planarflowml_val_loss = Column(PickleType)\n",
    "    planarflowml_epochs = Column(Integer)\n",
    "    planarflowml_init_params = Column(PickleType, nullable=True)\n",
    "    planarflowml_val_error_rate = Column(Float)\n",
    "\n",
    "    # radialflow:\n",
    "    radialflow_best_val_loss = Column(Float)\n",
    "    radialflow_best_parameters = Column(PickleType, nullable=True)\n",
    "    radialflow_train_loss = Column(PickleType)\n",
    "    radialflow_val_loss = Column(PickleType)\n",
    "    radialflow_epochs = Column(Integer)\n",
    "    radialflow_init_params = Column(PickleType, nullable=True)\n",
    "    radialflow_val_error_rate = Column(Float)\n",
    "\n",
    "    # radialflow deterministic:\n",
    "    radialflowdet_best_val_loss = Column(Float)\n",
    "    radialflowdet_best_parameters = Column(PickleType, nullable=True)\n",
    "    radialflowdet_train_loss = Column(PickleType)\n",
    "    radialflowdet_val_loss = Column(PickleType)\n",
    "    radialflowdet_epochs = Column(Integer)\n",
    "    radialflowdet_init_params = Column(PickleType, nullable=True)\n",
    "    radialflowdet_val_error_rate = Column(Float)\n",
    "\n",
    "    # radialflow maximum likelihood:\n",
    "    radialflowml_best_val_loss = Column(Float)\n",
    "    radialflowml_best_parameters = Column(PickleType, nullable=True)\n",
    "    radialflowml_train_loss = Column(PickleType)\n",
    "    radialflowml_val_loss = Column(PickleType)\n",
    "    radialflowml_epochs = Column(Integer)\n",
    "    radialflowml_init_params = Column(PickleType, nullable=True)\n",
    "    radialflowml_val_error_rate = Column(Float)\n",
    "\n",
    "    # mixture:\n",
    "    mixture_best_val_loss = Column(Float)\n",
    "    mixture_best_parameters = Column(PickleType, nullable=True)\n",
    "    mixture_train_loss = Column(PickleType)\n",
    "    mixture_val_loss = Column(PickleType)\n",
    "    mixture_epochs = Column(Integer)\n",
    "    mixture_init_params = Column(PickleType, nullable=True)\n",
    "    mixture_val_error_rate = Column(Float)\n",
    "\n",
    "    # mixture:\n",
    "    mixtureml_best_val_loss = Column(Float)\n",
    "    mixtureml_best_parameters = Column(PickleType, nullable=True)\n",
    "    mixtureml_train_loss = Column(PickleType)\n",
    "    mixtureml_val_loss = Column(PickleType)\n",
    "    mixtureml_epochs = Column(Integer)\n",
    "    mixtureml_init_params = Column(PickleType, nullable=True)\n",
    "    mixtureml_val_error_rate = Column(Float)\n",
    "\n",
    "    def __init__(self, hyper_dict=None):  # we directly refer to dict as sqlalchemy deletes the dict once committed (probably for detecting changes\n",
    "        if hyper_dict is not None:\n",
    "            for k, v in hyper_dict.iteritems():\n",
    "                if not k.startswith(\"_\"):\n",
    "                    setattr(self, k, copy(v))\n",
    "            self.init_results()\n",
    "            return\n",
    "        self.datasetname = datasetname\n",
    "        # hyper parameters:\n",
    "        self.max_epochs_without_improvement = 30\n",
    "        self.batch_size = random.choice([1,10, 100])\n",
    "        self.logP_average_n = 1\n",
    "        self.errorrate_average_n = 10\n",
    "        self.units_per_layer = 50\n",
    "        self.minus_log_s = random.choice([1,2,3,4,5,6,7])\n",
    "        # the prior is learned together with the other models in analogy to the paper Probabilistic Backpropagation\n",
    "        \n",
    "        self.n_normflows = random.choice([1,2,3,4,8,20])  #32 is to much for theano... unfortunately\n",
    "        \n",
    "        self.opt_identifier = random.choice([\"adadelta\", \"adam\", \"rmsprop\"])\n",
    "        if self.opt_identifier == \"adadelta\":\n",
    "            self.opt_momentum = random.choice([np.random.uniform(0, 0.01), np.random.uniform(0.9, 1)])\n",
    "            self.opt_offset = random.choice([5e-5, 1e-8])\n",
    "            self.opt_step_rate = random.choice([1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "        elif self.opt_identifier == \"adam\":\n",
    "            self.opt_momentum = random.choice([np.random.uniform(0, 0.01), np.random.uniform(0.8, 0.93)])\n",
    "            self.opt_offset = 10 ** -np.random.uniform(3, 4)\n",
    "            self.opt_step_rate = random.choice([1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "        elif self.opt_identifier == \"rmsprop\":\n",
    "            self.opt_momentum = random.choice([np.random.uniform(0.002, 0.008), np.random.uniform(0.9, 1)])\n",
    "            self.opt_offset = np.random.uniform(0, 0.000045)\n",
    "            self.opt_step_rate = random.choice([1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "        self.opt_decay = np.random.uniform(0.78, 1)\n",
    "        \n",
    "        self.init_results()\n",
    "    \n",
    "    def init_results(self):\n",
    "        # extra for being able to reset results for loaded hyperparameters\n",
    "        for prefix in ['baseline_', 'mixture_', 'mixtureml_',\n",
    "                       'planarflow_', 'planarflowdet_', 'planarflowml_',\n",
    "                       'radialflow_', 'radialflowdet_', 'radialflowml_']:\n",
    "            setattr(self, prefix + \"best_parameters\", None)\n",
    "            setattr(self, prefix + \"best_val_loss\", inf)\n",
    "            setattr(self, prefix + \"train_loss\", [])\n",
    "            setattr(self, prefix + \"val_loss\", [])\n",
    "            setattr(self, prefix + \"best_epoch\", 0)\n",
    "            setattr(self, prefix + \"init_params \", None)\n",
    "            setattr(self, prefix + \"val_error_rate\", inf)\n",
    "            \n",
    "Base.metadata.create_all()\n",
    "Session = sessionmaker(bind=engine)\n",
    "sql_session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyper = RandomHyper()\n",
    "sql_session.add(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060757143956466"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.opt_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyper.baseline_best_parameters = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(hyper, 'baseline_best_parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x7fd88c2bb4d0>,\n",
       " 'baseline_best_epoch': 0,\n",
       " 'baseline_init_params ': None,\n",
       " 'mixture_best_epoch': 0,\n",
       " 'mixture_init_params ': None,\n",
       " 'mixtureml_best_epoch': 0,\n",
       " 'mixtureml_init_params ': None,\n",
       " 'planarflow_best_epoch': 0,\n",
       " 'planarflow_init_params ': None,\n",
       " 'planarflowdet_best_epoch': 0,\n",
       " 'planarflowdet_init_params ': None,\n",
       " 'planarflowml_best_epoch': 0,\n",
       " 'planarflowml_init_params ': None,\n",
       " 'radialflow_best_epoch': 0,\n",
       " 'radialflow_init_params ': None,\n",
       " 'radialflowdet_best_epoch': 0,\n",
       " 'radialflowdet_init_params ': None,\n",
       " 'radialflowml_best_epoch': 0,\n",
       " 'radialflowml_init_params ': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060757143956466"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.opt_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlalchemy_test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
