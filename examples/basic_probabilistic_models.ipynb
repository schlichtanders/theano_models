{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from schlichtanders.myoptimizers import online, batch\n",
    "from schlichtanders.myfunctools import compose\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "from theano_models import flatten_parameters, reparameterize_map, softplus, softplus_inv, total_size\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.deterministic_models as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Gauss Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test we simply try to approximate a diagonal gaussian distribution to given gaussian samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 2\n",
    "model = pm.DiagGauss(size)\n",
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = pm.DiagGauss(init_mean=[4,10], init_var=[0.5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = target.function()\n",
    "sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 400\n",
    "targets = np.array([sampler() for _ in xrange(n_samples)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fit(fig, ax, time_delay=0.1):\n",
    "    \"\"\" interactive plot of model fit\n",
    "    \n",
    "    Plots target data set as well as two Ellipse around target and model mean with width/height = 2* respective\n",
    "    standard deviation.\n",
    "    \"\"\"\n",
    "    ax.clear()\n",
    "    ax.set_xlabel(\"x0\")\n",
    "    ax.set_ylabel(\"x1\")\n",
    "    \n",
    "    # plot data\n",
    "    # ---------\n",
    "    ax.plot(targets[:,0], targets[:,1], 'k.')\n",
    "    \n",
    "    # plot target\n",
    "    # -----------\n",
    "    target_mean = target.mean.eval()\n",
    "    target_var = target.var.eval()\n",
    "    \n",
    "    # Ellipse\n",
    "    e = Ellipse(target_mean, width=2*np.sqrt(target_var[0]), height=2*np.sqrt(target_var[1]))\n",
    "    e.set_clip_box(ax.bbox)\n",
    "    e.set_alpha(0.1)\n",
    "    e.set_facecolor([1, 0.1, 0.1])\n",
    "    ax.add_patch(e)\n",
    "\n",
    "    # plot model\n",
    "    # -----------\n",
    "    model_mean = model.mean.eval()\n",
    "    model_var = model.var.eval()\n",
    "    # text\n",
    "    ax.text(0.1, 0.2, 'm=%g,%g' % tuple(model_mean),\n",
    "            verticalalignment='bottom', horizontalalignment='left',\n",
    "            transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.1, 'v=%g,%g' % tuple(model_var),\n",
    "            verticalalignment='bottom', horizontalalignment='left',\n",
    "            transform=ax.transAxes)\n",
    "    # Ellipse\n",
    "    e = Ellipse(model_mean, width=2*np.sqrt(model_var[0]), height=2*np.sqrt(model_var[1]))\n",
    "    e.set_clip_box(ax.bbox)\n",
    "    e.set_alpha(0.2)\n",
    "    e.set_facecolor([0.1, 0.2, 0.4])\n",
    "    ax.add_patch(e)\n",
    "    # Point  # we need to add a normal plot, as then the axis adjust automatically\n",
    "    ax.plot(model_mean[0], model_mean[1], '+', color=[0.1, 0.2, 0.4], markersize=10)\n",
    "    \n",
    "    # interactively redraw\n",
    "    # --------------------\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(time_delay) # just because the fit is to fast otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_fit(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myoptimizer = opt.ScipyOptimizer(batch)\n",
    "# CAUTION: scipy args needs to be tuple in order to work as expected!\n",
    "myoptimizer.optimize(\n",
    "    model, args=(targets,),\n",
    "    method=\"Newton-CG\",\n",
    "    options={'maxiter':100, 'disp':True},\n",
    "    callback=lambda x: plot_fit(fig, ax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print model.var_from_Var(model._Var.get_value(), module=np)\n",
    "print model.mean.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation - TODO\n",
    "\n",
    "sometimes the above optimizer first overshoots the variance along x1 extremely (if the initial means are farer away, it is even worse).\n",
    "The resulting errors are either precision loss, or var[1] = inf. (tested on default optimizer BFGS)\n",
    "\n",
    "\n",
    "If I try the algorithms online, they almost immediately stop with precision loss ('Nelder-Mead' method does something, however needs extremely long and the variances are also not well approximated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pm.Uniform(size=2)\n",
    "m_sampler = model.function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = pm.Uniform(init_start=[1,4], init_offset=[2,1])\n",
    "t_sampler = target.function()\n",
    "t_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 400\n",
    "targets = np.array([t_sampler() for _ in xrange(n_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fit(fig, ax, time_delay=0.1):\n",
    "    ax.clear()\n",
    "    \n",
    "    # targets\n",
    "    ax.plot(targets[:,0], targets[:,1], \"k.\")\n",
    "    \n",
    "    # model\n",
    "    model_samples = np.array([m_sampler() for _ in xrange(n_samples)])\n",
    "    ax.plot(model_samples[:,0], model_samples[:,1], \"r.\")\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(time_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_fit(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myoptimizer = opt.ScipyOptimizer(batch)\n",
    "# CAUTION: scipy args needs to be tuple in order to work as expected!\n",
    "myoptimizer.optimize(\n",
    "    model, args=(targets,),\n",
    "#     method=\"Newton-CG\",\n",
    "    options={'maxiter':100, 'disp':True},\n",
    "    callback=lambda x: plot_fit(fig, ax)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO this does not work. Check whether the gradient is the reason (there is no gradient of the step probability function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test scipy minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure that everything is as thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse(a, *args, **kwargs):\n",
    "    aim = kwargs.pop('aim', np.array([42,3]))\n",
    "    print args\n",
    "    return np.sum((a - aim)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minimize(fun=mse, x0=np.array([1,-4]), args=[1,2], options={'maxiter': 10, 'disp': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
