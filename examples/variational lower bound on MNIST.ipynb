{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot, ylabel, xlabel, yscale, xscale, legend, subplots\n",
    "from theano import function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.data import one_hot\n",
    "from breze.learn.base import cast_array_to_local_type\n",
    "from schlichtanders.myfunctools import compose\n",
    "from schlichtanders.myoptimizers import batch\n",
    "from schlichtanders.mygenerators import eatN, chunk, every\n",
    "from schlichtanders.myplot import add_val, add_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_models import (as_tensor_variable, total_size, clone, clone_all,\n",
    "                           Merge, FlatKey, Reparameterize, squareplus, squareplus_inv,\n",
    "                           InvertibleModel,\n",
    "                           inputting_references, outputting_references)\n",
    "from theano_models.visualization import d3viz\n",
    "from IPython.display import IFrame\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.postmaps as post\n",
    "from theano_models.composing import normalizing_flow, variational_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano_models import get_equiv_by_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.printing import debugprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputting_references.update(['to_be_randomized'])\n",
    "inputting_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputting_references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "from theano.gof.graph import variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = T.dvectors(\"ab\")\n",
    "c = 2*a + b\n",
    "c.name = \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables([a,b], [c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile = '../data/mnist.pkl.gz'\n",
    "# Load data.        a                                                                                           \n",
    "\n",
    "with gzip.open(datafile,'rb') as f:                                                                        \n",
    "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
    "\n",
    "X, Z = train_set                                                                                               \n",
    "VX, VZ = val_set\n",
    "TX, TZ = test_set\n",
    "\n",
    "Z = one_hot(Z, 10)\n",
    "VZ = one_hot(VZ, 10)\n",
    "TZ = one_hot(TZ, 10)\n",
    "\n",
    "image_dims = 28, 28\n",
    "\n",
    "X, Z, VX, VZ, TX, TZ = [cast_array_to_local_type(i) for i in (X, Z, VX,VZ, TX, TZ)]\n",
    "map(np.shape, [X, Z, VX, VZ, TX, TZ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data modelling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for continous supervised data:\n",
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "post.flatten_parameters(predictor)\n",
    "\n",
    "target_distribution = pm.DiagGaussianNoise(predictor)\n",
    "\n",
    "targets = Merge(target_distribution, inputs=predictor['inputs'], to_be_randomized=predictor['parameters_flat'])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "# post.flatten_parameters(predictor)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_distribution = pm.Categorical(predictor)\n",
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = Merge(target_distribution, predictor, FlatKey(predictor, flat_key=\"to_be_randomized\"))\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_base = pm.DiagGauss(output_size=total_size(targets['to_be_randomized']))  # if you want to use size directly, CAUTION, you need to copy before!\n",
    "# params_base.map('parameters_positive', reparameterize_map(squareplus, squareplus_inv), 'parameters')\n",
    "params_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normflows = [dm.PlanarTransform() for _ in range(2)]\n",
    "normflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = params_base\n",
    "for transform in normflows:\n",
    "    params = normalizing_flow(transform, params)  # returns transform, however with adapted logP    \n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prior = pm.DiagGauss(targets['to_be_randomized'].size)\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = variational_bayes(targets, 'to_be_randomized', params, priors=prior)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Merge(model, Reparameterize(model['parameters_positive'], squareplus, squareplus_inv))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Merge(model, FlatKey(model, initial_inputs=[X[0]]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InvertibleModel.reduce_all_identities()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postmap = compose(post.flat_numericalize_postmap, post.variational_postmap)\n",
    "postmap_kwargs = {\n",
    "    'wrapper': batch,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01\n",
    "}\n",
    "optimizer_kwargs = postmap(model, **postmap_kwargs)\n",
    "climin_kwargs = post.climin_postmap(optimizer_kwargs)\n",
    "climin_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climin wants an iterator of (args, kwarsg) as keyword argument \"args\" (to be passed to the loss function). Concretley, we use an infinite iterator over minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "climin_args = izip(izip(chunk(batch_size, cycle(Z)), chunk(batch_size, cycle(X))), repeat({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = optimizer(\n",
    "    identifier = \"adadelta\",\n",
    "    args=climin_args, # repeat(((Z,X),{})),\n",
    "    **climin_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from theano_models import visualization\n",
    "visualization.CLUSTER_REFERENCE_GROUPS = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from theano_models import Subgraph\n",
    "next(sg for sg in Subgraph.all_subgraphs if \"normalized\" in sg.name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from theano_models import Subgraph\n",
    "Subgraph.all_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], model['outputs'], mode=\"FAST_COMPILE\")\n",
    "f = [model['flat']] + model['inputs'], model['outputs']\n",
    "d3viz(f, 'tmp/model.html', match_by_names=True) #, [targets, target_distribution, predictor, params] + predictor.layers + normflows + [params_base] + Helper.all_helpers[::-1])\n",
    "IFrame('tmp/model.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import webbrowser\n",
    "web = webbrowser.get('google-chrome')\n",
    "web.open_new_tab('tmp/model.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from theano_models import Subgraph\n",
    "next(m for m in Subgraph.all_subgraphs if \"variational\" in m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], optimizer_kwargs['loss'], mode=\"FAST_COMPILE\", profile=True)\n",
    "f = [model['flat']] + model['inputs'], optimizer_kwargs['loss']\n",
    "d3viz(f, 'tmp/loss.html')\n",
    "IFrame('tmp/loss.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_train, = plot([], [], 'go-', label=\"average training loss\")\n",
    "line_curr_val, = plot([],[], 'bo:', label=\"avrg current validation loss\")\n",
    "line_best_val, = plot([], [], 'ko-', label=\"avrg best validation loss\")\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "yscale('log')\n",
    "ylabel(\"validation loss\")\n",
    "xlabel(\"#iteration\")\n",
    "legend(loc='lower left', fancybox=True, framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = inf\n",
    "best_wrt = None\n",
    "val_size = batch_size\n",
    "\n",
    "n_whole_data = X.shape[0] // batch_size\n",
    "\n",
    "for info in every(n_whole_data, opt):\n",
    "    # collect and visualize validation loss for choosing the best model\n",
    "    val_loss = optimizer_kwargs['num_loss'](opt.wrt, VZ[:val_size], VX[:val_size])/val_size\n",
    "    if val_loss < best_val_loss:\n",
    "        best_wrt = opt.wrt\n",
    "        best_val_loss = val_loss\n",
    "        add_point(line_best_val, info['n_iter'], val_loss)\n",
    "    add_point(line_curr_val, info['n_iter'], val_loss)\n",
    "    \n",
    "    # visualize training loss for comparison:\n",
    "    try:\n",
    "        training_loss = info['loss'] / len(Z)  # TODO normalization needed?\n",
    "    except KeyError:\n",
    "        training_loss = optimizer_kwargs['num_loss'](opt.wrt, Z, X)/len(Z)\n",
    "    add_point(line_train, info['n_iter'], training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: average over predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_val_loss\n",
    "mlp['parameters_flat'] = best_wrt\n",
    "\n",
    "predict = mlp.function()\n",
    "predict(X[0]), Z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PX = np.apply_along_axis(predict, 1, X)\n",
    "PVX = np.apply_along_axis(predict, 1, VX)\n",
    "PTX = np.apply_along_axis(predict, 1, TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'incorrect samples train/val/test:  %i/%i/%i' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).sum(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).sum(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).sum())\n",
    "\n",
    "print 'error rate train/val/test:  %g/%g/%g' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).mean(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).mean(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
