{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot, ylabel, xlabel, yscale, xscale, legend, subplots\n",
    "from theano import function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.data import one_hot\n",
    "from breze.learn.base import cast_array_to_local_type\n",
    "from schlichtanders.myfunctools import compose, meanmap, summap\n",
    "from schlichtanders.mygenerators import eatN, chunk, chunk_list, every\n",
    "from schlichtanders.myplot import add_val, add_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_models import (as_tensor_variable, total_size, clone, clone_all,\n",
    "                           Merge, Flatten, Reparameterize, squareplus, squareplus_inv,\n",
    "                           InvertibleModel,\n",
    "                           inputting_references, outputting_references,\n",
    "                           PooledRandomStreams,\n",
    "                           get_profile)\n",
    "from theano_models.util.theano_helpers import independent_subgraphs    \n",
    "from theano_models.visualization import d3viz\n",
    "from IPython.display import IFrame\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.extra_models as em\n",
    "import theano_models.postmaps as post\n",
    "from theano_models.composing import normalizing_flow, variational_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.printing import debugprint\n",
    "from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'flat',\n",
       "  'inputs',\n",
       "  'n_data',\n",
       "  'noise',\n",
       "  'parameters',\n",
       "  'parameters_positive',\n",
       "  'parameters_pvalues',\n",
       "  'to_be_randomized'},\n",
       " {'kl_prior', 'logP', 'loglikelihood', 'norm_det', 'outputs'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputting_references.update(['to_be_randomized'])\n",
    "inputting_references, outputting_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from schlichtanders.myobjects import NestedNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pm.RNG = NestedNamespace(PooledRandomStreams(), RandomStreams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 784),\n",
       " (50000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = '../data/mnist.pkl.gz'\n",
    "# Load data.        a                                                                                           \n",
    "\n",
    "with gzip.open(datafile,'rb') as f:                                                                        \n",
    "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
    "\n",
    "X, Z = train_set                                                                                               \n",
    "VX, VZ = val_set\n",
    "TX, TZ = test_set\n",
    "\n",
    "Z = one_hot(Z, 10)\n",
    "VZ = one_hot(VZ, 10)\n",
    "TZ = one_hot(TZ, 10)\n",
    "\n",
    "image_dims = 28, 28\n",
    "\n",
    "X, Z, VX, VZ, TX, TZ = [cast_array_to_local_type(i) for i in (X, Z, VX,VZ, TX, TZ)]\n",
    "map(np.shape, [X, Z, VX, VZ, TX, TZ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data modelling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for continous supervised data:\n",
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "post.flatten_parameters(predictor)\n",
    "\n",
    "target_distribution = pm.DiagGaussianNoise(predictor)\n",
    "\n",
    "targets = Merge(target_distribution, inputs=predictor['inputs'], to_be_randomized=predictor['parameters_flat'])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mlp { 'inputs': [X],\n",
       "  'outputs': AffineNonlinear2.outputs,\n",
       "  'parameters': [weights, bias, weights2, bias2]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = as_tensor_variable(X[0], name=\"X\")  # this is extremely useful to tell everything the default sizes\n",
    "predictor = dm.Mlp(input=input, output_size=10, output_transfer=\"softmax\", hidden_sizes=[300]*1, hidden_transfers=[\"rectifier\"]*1)\n",
    "# post.flatten_parameters(predictor)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f3734b8b9f0 for function at 0x7f3734ce0f50>,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters_pvalues': [AffineNonlinear2.outputs]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution = pm.Categorical(predictor)\n",
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge { 'inputs': [X],\n",
       "  'logP': <FunctionWrapper at 0x7f3734b8b9f0 for function at 0x7f3734ce0f50>,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_pvalues': [],\n",
       "  'to_be_randomized': \"weights:bias:weights2:bias2\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = Merge(target_distribution, predictor,\n",
    "                Flatten(predictor['parameters'], flat_key=\"to_be_randomized\")) #givens={predictor['inputs'][0]: X[0]}\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<schlichtanders.myobjects.NestedNamespace object at 0x7f373501ec10>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiagGauss { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f372c2e5fa0 for function at 0x7f372c2e79b0>,\n",
       "  'noise': [DiagGaussianNoise.noise.0],\n",
       "  'outputs': DiagGaussianNoise.outputs,\n",
       "  'parameters': [mean],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_base = pm.DiagGauss(output_size=total_size(targets['to_be_randomized']))  \n",
    "# if you want to use size directly, CAUTION, you need to copy before!\n",
    "# params_base.map('parameters_positive', reparameterize_map(squareplus, squareplus_inv), 'parameters')\n",
    "params_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PlanarTransform { 'inputs': [z],\n",
       "   'norm_det': PlanarTransform.norm_det,\n",
       "   'outputs': PlanarTransform.outputs,\n",
       "   'parameters': [b, w, _u]}, PlanarTransform2 { 'inputs': [z2],\n",
       "   'norm_det': PlanarTransform2.norm_det,\n",
       "   'outputs': PlanarTransform2.outputs,\n",
       "   'parameters': [b2, w2, _u2]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normflows = [dm.PlanarTransform() for _ in range(2)]\n",
    "normflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_flow2 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f372c056bb0 for function at 0x7f372c077500>,\n",
       "  'noise': [DiagGaussianNoise.noise.0],\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': PlanarTransform2.outputs,\n",
       "  'parameters': [b2, w2, _u2, b, w, _u, mean],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = params_base\n",
    "for transform in normflows:\n",
    "    params = normalizing_flow(transform, params)  # returns transform, however with adapted logP    \n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<schlichtanders.myobjects.NestedNamespace object at 0x7f373501ec10>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Merge2 { 'hyperparameters_positive': [var2],\n",
       "  'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f372c056c20 for function at 0x7f372c00c8c0>,\n",
       "  'noise': [GaussianNoise.noise.0],\n",
       "  'outputs': GaussianNoise.outputs,\n",
       "  'parameters': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = pm.Gauss(total_size(targets['to_be_randomized']))\n",
    "prior = Merge(prior, parameters=None, parameters_positive='hyperparameters_positive')  # mean is not adapted at all, but left centred at zero\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variational_lower_bound { 'hyperparameters_positive': [var2],\n",
       "  'inputs': [X],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f372bfd3c20 for function at 0x7f372c00cc08>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3734b8b9f0 for function at 0x7f3734ce0f50>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [DiagGaussianNoise.noise.0, GaussianNoise.noise.0],\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [b2, w2, _u2, b, w, _u, mean],\n",
       "  'parameters_positive': [var],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = variational_bayes(targets, 'to_be_randomized', params, priors=prior)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge3 { 'hyperparameters_positive': [var2],\n",
       "  'inputs': [X],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f372bfd3c20 for function at 0x7f372c00cc08>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3734b8b9f0 for function at 0x7f3734ce0f50>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [DiagGaussianNoise.noise.0, GaussianNoise.noise.0],\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [b2, w2, _u2, b, w, _u, mean, var_squareplus],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model, Reparameterize(model['parameters_positive'], squareplus, squareplus_inv))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge4 { 'flat': \"b2:w2:_u2:b:w:_u:mean:var_squareplus\",\n",
       "  'hyperparameters_positive': [var2],\n",
       "  'inputs': [X],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f372bfd3c20 for function at 0x7f372c00cc08>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3734b8b9f0 for function at 0x7f3734ce0f50>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [DiagGaussianNoise.noise.0, GaussianNoise.noise.0],\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model, Flatten(model['parameters']))\n",
    "#               em.NoisePool(model['noise']) #, givens={predictor['inputs'][0]: X[0]}\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InvertibleModel.reduce_all_identities()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': <function theano_models.postmaps.f>,\n",
       " 'fprime': <function theano_models.postmaps.f>,\n",
       " 'wrt': array([ 0.00363809,  0.99810852,  0.98554348, ...,  0.99443316,\n",
       "         1.00445695,  1.00600495])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postmap2 = compose(post.flat_numericalize_postmap, post.variational_postmap)\n",
    "postmap2_kwargs = {\n",
    "    'pre_compile_parameters_subgraph': True,\n",
    "    'mapreduce': meanmap,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01,\n",
    "    'profile': True,\n",
    "    'mode': 'FAST_RUN'\n",
    "}\n",
    "optimizer_kwargs2 = postmap2(model, **postmap2_kwargs)\n",
    "climin_kwargs2 = post.climin_postmap(optimizer_kwargs2)\n",
    "climin_kwargs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': <function theano_models.postmaps.f>,\n",
       " 'fprime': <function theano_models.postmaps.f>,\n",
       " 'wrt': array([ 0.00466673,  0.99332328,  0.98903858, ...,  0.99887573,\n",
       "         1.00753159,  0.99406263])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postmap = compose(post.flat_numericalize_postmap, post.variational_postmap)\n",
    "postmap_kwargs = {\n",
    "    'mapreduce': meanmap,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01,\n",
    "    'profile': True,\n",
    "    'mode': 'FAST_RUN'\n",
    "}\n",
    "optimizer_kwargs = postmap(model, **postmap_kwargs)\n",
    "climin_kwargs = post.climin_postmap(optimizer_kwargs)\n",
    "climin_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climin wants an iterator of (args, kwarsg) as keyword argument \"args\" (to be passed to the loss function). Concretley, we use an infinite iterator over minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO write chunk with O(M) M=number of minibatches\n",
    "the current implementation is O(N) N=number of samples, because of use of generators instead of list slicing\n",
    "\n",
    "try to use ``chunk_gen``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "climin_args = izip(izip(chunk(batch_size, cycle(Z)), chunk(batch_size, cycle(X))), repeat({}))\n",
    "# climin_args = repeat(((Z[:10],X[:10]),{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/GitProjects/breze/src/climin/climin/util.py:151: UserWarning: Argument named f is not expected by <class 'climin.adadelta.Adadelta'>\n",
      "  % (i, klass))\n"
     ]
    }
   ],
   "source": [
    "opt = optimizer(\n",
    "    identifier = \"adadelta\",\n",
    "    args=climin_args,\n",
    "    **climin_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], model['outputs'], mode=\"FAST_COMPILE\")\n",
    "f = [model['flat']] + model['inputs'], model['outputs']\n",
    "d3viz(f, 'tmp/model.html', match_by_names=True) #, [targets, target_distribution, predictor, params] + predictor.layers + normflows + [params_base] + Helper.all_helpers[::-1])\n",
    "IFrame('tmp/model.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import webbrowser\n",
    "web = webbrowser.get('google-chrome')\n",
    "web.open_new_tab('tmp/model.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs['num_loss'](optimizer_kwargs['num_parameters'], Z[0:1], X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs2['num_loss'](optimizer_kwargs2['num_parameters'], Z[0:1], X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 110 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs['num_loss'](optimizer_kwargs['num_parameters'], Z[0:10], X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 12.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs2['num_loss'](optimizer_kwargs2['num_parameters'], Z[0:10], X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.12 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs['num_loss'](optimizer_kwargs['num_parameters'], Z[0:100], X[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 27 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit optimizer_kwargs2['num_loss'](optimizer_kwargs2['num_parameters'], Z[0:100], X[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observable that the second variant is much much better if it comes to multiple batches. All what was done is to extract the parameter-only dependent part and compute this one single time per batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "f = optimizer_kwargs['num_loss'].wrapped\n",
    "d3viz(f, 'tmp/loss.html', match_by_names=True)\n",
    "IFrame('tmp/loss.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_profile(f).fct_call_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing gradient"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "optimizer_kwargs['num_jacobian'](optimizer_kwargs['num_parameters'], Z[0:1], X[0:1])\n",
    "\n",
    "f = optimizer_kwargs['num_jacobian'].wrapped\n",
    "d3viz(f, 'tmp/gradient.html', match_by_names=True)\n",
    "IFrame('tmp/gradient.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_profile(f).fct_call_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized Fit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "line_train, = plot([], [], 'go-', label=\"average training loss\")\n",
    "line_curr_val, = plot([],[], 'bo:', label=\"avrg current validation loss\")\n",
    "line_best_val, = plot([], [], 'ko-', label=\"avrg best validation loss\")\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "yscale('log')\n",
    "ylabel(\"validation loss\")\n",
    "xlabel(\"#iteration\")\n",
    "legend(loc='lower left', fancybox=True, framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = inf\n",
    "best_wrt = None\n",
    "val_size = 10 #batch_size\n",
    "\n",
    "n_whole_data = X.shape[0] // batch_size\n",
    "print n_whole_data\n",
    "\n",
    "for info in opt:\n",
    "    # collect and visualize validation loss for choosing the best model\n",
    "    val_loss = optimizer_kwargs['num_loss'](opt.wrt, VZ[:val_size], VX[:val_size]) #/val_size\n",
    "    if val_loss < best_val_loss:\n",
    "        best_wrt = opt.wrt\n",
    "        best_val_loss = val_loss\n",
    "#         add_point(line_best_val, info['n_iter'], val_loss)\n",
    "#     add_point(line_curr_val, info['n_iter'], val_loss)\n",
    "    \n",
    "    # visualize training loss for comparison:\n",
    "    try:\n",
    "        training_loss = info['loss'] #/ len(Z)  # TODO normalization needed?\n",
    "    except KeyError:\n",
    "        training_loss = optimizer_kwargs['num_loss'](opt.wrt, Z[:val_size, X[:val_size]) #/len(Z)\n",
    "#     add_point(line_train, info['n_iter'], training_loss)\n",
    "    print info['n_iter'], training_loss, val_loss, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: average over predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_val_loss\n",
    "mlp['parameters_flat'] = best_wrt\n",
    "\n",
    "predict = mlp.function()\n",
    "predict(X[0]), Z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PX = np.apply_along_axis(predict, 1, X)\n",
    "PVX = np.apply_along_axis(predict, 1, VX)\n",
    "PTX = np.apply_along_axis(predict, 1, TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'incorrect samples train/val/test:  %i/%i/%i' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).sum(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).sum(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).sum())\n",
    "\n",
    "print 'error rate train/val/test:  %g/%g/%g' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).mean(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).mean(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
