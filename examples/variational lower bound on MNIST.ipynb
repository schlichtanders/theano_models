{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot, ylabel, xlabel, yscale, xscale, legend, subplots\n",
    "from theano import function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.data import one_hot\n",
    "from breze.learn.base import cast_array_to_local_type\n",
    "from schlichtanders.myfunctools import compose\n",
    "from schlichtanders.myoptimizers import batch\n",
    "from schlichtanders.mygenerators import eatN, chunk, every\n",
    "from schlichtanders.myplot import add_val, add_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_models import (as_tensor_variable, total_size, Merge, clone, clone_all,\n",
    "                           reparameterize, squareplus, squareplus_inv, pmerge_key_reparam,\n",
    "                           InvertibleModel)\n",
    "from theano_models.visualization import d3viz\n",
    "from IPython.display import IFrame\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.postmaps as post\n",
    "from theano_models.composing import normalizing_flow, variational_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano_models.util.theano_helpers import get_dependencies, sort_dependent_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.printing import debugprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 784),\n",
       " (50000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = '../data/mnist.pkl.gz'\n",
    "# Load data.        a                                                                                           \n",
    "\n",
    "with gzip.open(datafile,'rb') as f:                                                                        \n",
    "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
    "\n",
    "X, Z = train_set                                                                                               \n",
    "VX, VZ = val_set\n",
    "TX, TZ = test_set\n",
    "\n",
    "Z = one_hot(Z, 10)\n",
    "VZ = one_hot(VZ, 10)\n",
    "TZ = one_hot(TZ, 10)\n",
    "\n",
    "image_dims = 28, 28\n",
    "\n",
    "X, Z, VX, VZ, TX, TZ = [cast_array_to_local_type(i) for i in (X, Z, VX,VZ, TX, TZ)]\n",
    "map(np.shape, [X, Z, VX, VZ, TX, TZ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'inputs': [<TensorType(float64, vector)>],\n",
       "  'logP': <FunctionWrapper at 0x7fa483cd2910 for function at 0x7fa483d2cd70>,\n",
       "  'outputs': Elemwise{add,no_inplace}.0,\n",
       "  'parameters': [],\n",
       "  'parameters_positive': [var],\n",
       "  'to_be_randomized': weights_copy:bias_copy:weights_copy:bias_copy:weights_copy:bias_copy}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "post.flatten_parameters(predictor)\n",
    "\n",
    "noise = pm.DiagGaussianNoise(predictor)\n",
    "\n",
    "targets = Merge(noise, inputs=predictor['inputs'], to_be_randomized=predictor['parameters_flat'])\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'inputs': [],\n",
       "  'inverse_inputs': [inverse_inputs],\n",
       "  'inverse_outputs': inverse_outputs,\n",
       "  'logP': <FunctionWrapper at 0x7fa483ca6980 for function at 0x7fa483ca5a28>,\n",
       "  'norm_det': Elemwise{add,no_inplace}.0,\n",
       "  'outputs': f_outputs,\n",
       "  'parameters': [b, w, _u, mean, b, w, _u],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_base = pm.DiagGauss(output_size=total_size(targets['to_be_randomized']))  # if you want to use size directly, CAUTION, you need to copy before!\n",
    "# params_base.map('parameters_positive', reparameterize_map(squareplus, squareplus_inv), 'parameters')\n",
    "\n",
    "normflows = [dm.PlanarTransform() for _ in range(2)]\n",
    "params_cur = params_base\n",
    "for transform in normflows:\n",
    "    params_cur = normalizing_flow(transform, params_cur)  # returns transform, however with adapted logP    \n",
    "\n",
    "params = Merge(params_cur, params_base, *normflows[:-1])  # last one is params_cur\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No substitution as `self[logP]` is not a theano.gof.Variable. Key is simply replaced.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{ 'inputs': [<TensorType(float64, vector)>],\n",
       "  'kl_prior': Elemwise{sub,no_inplace}.0,\n",
       "  'logP': <FunctionWrapper at 0x7fa483c6e1a0 for function at 0x7fa483ca5410>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7fa483cd2910 for function at 0x7fa483d2cd70>,\n",
       "  'n_data': <TensorType(int64, scalar)>,\n",
       "  'outputs': Elemwise{add,no_inplace}.0,\n",
       "  'parameters': [ b,\n",
       "                  w,\n",
       "                  _u,\n",
       "                  mean,\n",
       "                  b,\n",
       "                  w,\n",
       "                  _u,\n",
       "                  mean_prior,\n",
       "                  var_squareplus,\n",
       "                  var_squareplus,\n",
       "                  var_squareplus],\n",
       "  'parameters_positive': [var_reparam, var_reparam, var_reparam],\n",
       "  'to_be_randomized': inverse_outputs}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = pm.DiagGauss(targets['to_be_randomized'].size)\n",
    "prior.mean.name = \"mean_prior\"\n",
    "\n",
    "variational_bayes(targets, 'to_be_randomized', params, priors=prior)\n",
    "\n",
    "model = Merge(targets, params, prior, parameters=pmerge_key_reparam(squareplus, squareplus_inv))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model { 'inputs': [<TensorType(float64, vector)>],\n",
      "  'kl_prior': Elemwise{sub,no_inplace}.0,\n",
      "  'logP': <FunctionWrapper at 0x7fa483c6e1a0 for function at 0x7fa483ca5410>,\n",
      "  'loglikelihood': <FunctionWrapper at 0x7fa483cd2910 for function at 0x7fa483d2cd70>,\n",
      "  'n_data': <TensorType(int64, scalar)>,\n",
      "  'outputs': Elemwise{add,no_inplace}.0,\n",
      "  'parameters': [],\n",
      "  'parameters_positive': [var_reparam],\n",
      "  'to_be_randomized': inverse_outputs} defaultdict(<type 'list'>, {'ext_outputs': [(Elemwise{add,no_inplace}.0, 'n1')], 'ext_inputs': ['n3']})\n",
      "model { 'inputs': [Reshape{1}.0],\n",
      "  'logP': <FunctionWrapper at 0x7fa483cd2910 for function at 0x7fa483d2cd70>,\n",
      "  'outputs': Elemwise{add,no_inplace}.0,\n",
      "  'parameters': [],\n",
      "  'parameters_positive': [var_reparam]} defaultdict(<type 'list'>, {'ext_outputs': [(Elemwise{add,no_inplace}.0, 'n21')], 'ext_inputs': ['n24']})\n",
      "model { 'inputs': [<TensorType(float64, vector)>],\n",
      "  'outputs': Reshape{1}.0,\n",
      "  'parameters': [ weights_flat,\n",
      "                  bias_flat,\n",
      "                  weights_flat,\n",
      "                  bias_flat,\n",
      "                  weights_flat,\n",
      "                  bias_flat],\n",
      "  'parameters_flat': inverse_outputs} defaultdict(<type 'list'>, {'ext_inputs': ['n23']})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_nested_model() takes exactly 7 arguments (6 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6cac1310ac6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md3viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnormflows\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparams_base\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tmp/visualization.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mIFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tmp/visualization.html'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/theano_models/visualization/__init__.py\u001b[0m in \u001b[0;36md3viz\u001b[1;34m(th_graph, models, outfile, copy_deps, *args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# Create DOT graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyPyDotFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[0mdot_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/theano_models/visualization/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, th_graph, models, dot_graph)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdot_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msub_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/theano_models/visualization/__init__.py\u001b[0m in \u001b[0;36mmake_nested_model\u001b[1;34m(self, m, models, profile, ext_inputs, ext_outputs, dot_graph)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mgf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyPyDotFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mgf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__node_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mdot_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/stephan/GitProjects/theano_models/theano_models/visualization/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, th_graph, models, dot_graph)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdot_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msub_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: make_nested_model() takes exactly 7 arguments (6 given)"
     ]
    }
   ],
   "source": [
    "d3viz(model, [targets, noise, predictor, params] + normflows + [params_base], 'tmp/visualization.html')\n",
    "IFrame('tmp/visualization.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "InvertibleModel.reduce_all_identities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postmap = compose(post.flat_numericalize_postmap, post.variational_postmap, post.flatten_parameters)\n",
    "postmap_kwargs = {\n",
    "    'wrapper': batch,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01\n",
    "}\n",
    "optimizer_kwargs = postmap(model, **postmap_kwargs)\n",
    "post.climin_postmap(optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climin wants an iterator of (args, kwarsg) as keyword argument \"args\" (to be passed to the loss function). Concretley, we use an infinite iterator over minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "climin_args = izip(izip(chunk(batch_size, cycle(Z)), chunk(batch_size, cycle(X))), repeat({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = optimizer(\n",
    "    identifier = \"adadelta\",\n",
    "    args=climin_args, # repeat(((Z,X),{})),\n",
    "    **post.climin_postmap(optimizer_kwargs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_train, = plot([], [], 'go-', label=\"average training loss\")\n",
    "line_curr_val, = plot([],[], 'bo:', label=\"avrg current validation loss\")\n",
    "line_best_val, = plot([], [], 'ko-', label=\"avrg best validation loss\")\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "yscale('log')\n",
    "ylabel(\"validation loss\")\n",
    "xlabel(\"#iteration\")\n",
    "legend(loc='lower left', fancybox=True, framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = inf\n",
    "best_wrt = None\n",
    "val_size = batch_size\n",
    "\n",
    "n_whole_data = X.shape[0] // batch_size\n",
    "\n",
    "for info in every(n_whole_data, opt):\n",
    "    # collect and visualize validation loss for choosing the best model\n",
    "    val_loss = optimizer_kwargs['num_loss'](opt.wrt, VZ[:val_size], VX[:val_size])/val_size\n",
    "    if val_loss < best_val_loss:\n",
    "        best_wrt = opt.wrt\n",
    "        best_val_loss = val_loss\n",
    "        add_point(line_best_val, info['n_iter'], val_loss)\n",
    "    add_point(line_curr_val, info['n_iter'], val_loss)\n",
    "    \n",
    "    # visualize training loss for comparison:\n",
    "    try:\n",
    "        training_loss = info['loss'] / len(Z)  # TODO normalization needed?\n",
    "    except KeyError:\n",
    "        training_loss = optimizer_kwargs['num_loss'](opt.wrt, Z, X)/len(Z)\n",
    "    add_point(line_train, info['n_iter'], training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: average over predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_val_loss\n",
    "mlp['parameters_flat'] = best_wrt\n",
    "\n",
    "predict = mlp.function()\n",
    "predict(X[0]), Z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PX = np.apply_along_axis(predict, 1, X)\n",
    "PVX = np.apply_along_axis(predict, 1, VX)\n",
    "PTX = np.apply_along_axis(predict, 1, TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'incorrect samples train/val/test:  %i/%i/%i' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).sum(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).sum(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).sum())\n",
    "\n",
    "print 'error rate train/val/test:  %g/%g/%g' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).mean(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).mean(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
