{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot, ylabel, xlabel, yscale, xscale, legend, subplots\n",
    "from theano import function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.data import one_hot\n",
    "from breze.learn.base import cast_array_to_local_type\n",
    "from schlichtanders.myfunctools import compose\n",
    "from schlichtanders.myoptimizers import batch\n",
    "from schlichtanders.mygenerators import eatN, chunk, every\n",
    "from schlichtanders.myplot import add_val, add_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_models import (as_tensor_variable, total_size, clone, clone_all,\n",
    "                           Merge, FlatKey, Reparameterize, squareplus, squareplus_inv,\n",
    "                           InvertibleModel,\n",
    "                           inputting_references, outputting_references)\n",
    "from theano_models.visualization import d3viz\n",
    "from IPython.display import IFrame\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.postmaps as post\n",
    "from theano_models.composing import normalizing_flow, variational_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano_models.util.theano_helpers import get_dependencies, sort_dependent_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.printing import debugprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flat',\n",
       " 'inputs',\n",
       " 'inverse_inputs',\n",
       " 'n_data',\n",
       " 'parameters',\n",
       " 'parameters_positive',\n",
       " 'parameters_pvalues',\n",
       " 'to_be_randomized'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputting_references.update(['to_be_randomized'])\n",
    "inputting_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inverse_outputs', 'kl_prior', 'logP', 'loglikelihood', 'norm_det', 'outputs'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputting_references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 784),\n",
       " (50000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = '../data/mnist.pkl.gz'\n",
    "# Load data.        a                                                                                           \n",
    "\n",
    "with gzip.open(datafile,'rb') as f:                                                                        \n",
    "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
    "\n",
    "X, Z = train_set                                                                                               \n",
    "VX, VZ = val_set\n",
    "TX, TZ = test_set\n",
    "\n",
    "Z = one_hot(Z, 10)\n",
    "VZ = one_hot(VZ, 10)\n",
    "TZ = one_hot(TZ, 10)\n",
    "\n",
    "image_dims = 28, 28\n",
    "\n",
    "X, Z, VX, VZ, TX, TZ = [cast_array_to_local_type(i) for i in (X, Z, VX,VZ, TX, TZ)]\n",
    "map(np.shape, [X, Z, VX, VZ, TX, TZ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data modelling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for continous supervised data:\n",
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "post.flatten_parameters(predictor)\n",
    "\n",
    "target_distribution = pm.DiagGaussianNoise(predictor)\n",
    "\n",
    "targets = Merge(target_distribution, inputs=predictor['inputs'], to_be_randomized=predictor['parameters_flat'])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mlp { 'inputs': [AffineNonlinear.inputs.0],\n",
       "  'outputs': AffineNonlinear3.outputs,\n",
       "  'parameters': [weights, bias, weights, bias, weights, bias]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "# post.flatten_parameters(predictor)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters_pvalues': [AffineNonlinear3.outputs]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution = pm.Categorical(predictor)\n",
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters_pvalues': [AffineNonlinear3.outputs]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge { 'inputs': [AffineNonlinear.inputs.0],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_pvalues': [],\n",
       "  'to_be_randomized': \"weights_copy:bias_copy:weights_copy:bias_copy:weights_copy:bias_copy\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = Merge(target_distribution, predictor, FlatKey(predictor, flat_key=\"to_be_randomized\"))\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagGauss { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8dfb6d70 for function at 0x7fdb8e091d70>,\n",
       "  'outputs': DiagGaussianNoise.outputs,\n",
       "  'parameters': [mean],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_base = pm.DiagGauss(output_size=total_size(targets['to_be_randomized']))  # if you want to use size directly, CAUTION, you need to copy before!\n",
    "# params_base.map('parameters_positive', reparameterize_map(squareplus, squareplus_inv), 'parameters')\n",
    "params_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PlanarTransform { 'inputs': [z],\n",
       "   'norm_det': PlanarTransform.norm_det,\n",
       "   'outputs': PlanarTransform.outputs,\n",
       "   'parameters': [b, w, _u]}, PlanarTransform2 { 'inputs': [z],\n",
       "   'norm_det': PlanarTransform2.norm_det,\n",
       "   'outputs': PlanarTransform2.outputs,\n",
       "   'parameters': [b, w, _u]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normflows = [dm.PlanarTransform() for _ in range(2)]\n",
    "normflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_flow2 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8defd1a0 for function at 0x7fdb8deab578>,\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': PlanarTransform2.outputs,\n",
       "  'parameters': [b, w, _u, b, w, _u, mean],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = params_base\n",
    "for transform in normflows:\n",
    "    params = normalizing_flow(transform, params)  # returns transform, however with adapted logP    \n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagGauss2 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7fdb8defd210 for function at 0x7fdb8deab320>,\n",
       "  'outputs': DiagGaussianNoise2.outputs,\n",
       "  'parameters': [mean_prior],\n",
       "  'parameters_positive': [var]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = pm.DiagGauss(targets['to_be_randomized'].size)\n",
    "prior.mean.name = \"mean_prior\"\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variational_lower_bound { 'inputs': [AffineNonlinear.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7fdb8dee9360 for function at 0x7fdb8deb40c8>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'n_data': n_data,\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [b, w, _u, b, w, _u, mean, mean_prior],\n",
       "  'parameters_positive': [var, var],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = variational_bayes(targets, 'to_be_randomized', params, priors=prior)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge2 { 'inputs': [AffineNonlinear.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7fdb8dee9360 for function at 0x7fdb8deb40c8>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'n_data': n_data,\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [ b,\n",
       "                  w,\n",
       "                  _u,\n",
       "                  b,\n",
       "                  w,\n",
       "                  _u,\n",
       "                  mean,\n",
       "                  mean_prior,\n",
       "                  var_squareplus,\n",
       "                  var_squareplus],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model, Reparameterize(model['parameters_positive'], squareplus, squareplus_inv))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge3 { 'flat': \"b:w:_u:b:w:_u:mean:mean_prior:var_squareplus:var_squareplus\",\n",
       "  'inputs': [AffineNonlinear.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7fdb8dee9360 for function at 0x7fdb8deb40c8>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7fdb8e068c90 for function at 0x7fdb8e0ff848>,\n",
       "  'n_data': n_data,\n",
       "  'norm_det': PlanarTransform2.norm_det,\n",
       "  'outputs': Categorical.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model, FlatKey(model, initial_inputs=[X[0]]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InvertibleModel.reduce_all_identities()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': <function schlichtanders.myoptimizers.f_batch>,\n",
       " 'fprime': <function schlichtanders.myoptimizers.f_batch>,\n",
       " 'wrt': array([ 0.00437581,  1.0095916 ,  0.99145387, ...,  1.00682627,\n",
       "         0.99813531,  1.00202845])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postmap = compose(post.flat_numericalize_postmap, post.variational_postmap)\n",
    "postmap_kwargs = {\n",
    "    'wrapper': batch,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01\n",
    "}\n",
    "optimizer_kwargs = postmap(model, **postmap_kwargs)\n",
    "climin_kwargs = post.climin_postmap(optimizer_kwargs)\n",
    "climin_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climin wants an iterator of (args, kwarsg) as keyword argument \"args\" (to be passed to the loss function). Concretley, we use an infinite iterator over minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "climin_args = izip(izip(chunk(batch_size, cycle(Z)), chunk(batch_size, cycle(X))), repeat({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/GitProjects/breze/src/climin/climin/util.py:151: UserWarning: Argument named f is not expected by <class 'climin.adadelta.Adadelta'>\n",
      "  % (i, klass))\n"
     ]
    }
   ],
   "source": [
    "opt = optimizer(\n",
    "    identifier = \"adadelta\",\n",
    "    args=climin_args, # repeat(((Z,X),{})),\n",
    "    **climin_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from theano_models import visualization\n",
    "visualization.CLUSTER_REFERENCE_GROUPS = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from theano_models import Subgraph\n",
    "next(sg for sg in Subgraph.all_subgraphs if \"normalized\" in sg.name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from theano_models import Subgraph\n",
    "Subgraph.all_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"500\"\n",
       "            src=\"tmp/model.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdb8e14de50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], model['outputs'], mode=\"FAST_COMPILE\")\n",
    "f = [model['flat']] + model['inputs'], model['outputs']\n",
    "d3viz(f, 'tmp/model.html') #, [targets, target_distribution, predictor, params] + predictor.layers + normflows + [params_base] + Helper.all_helpers[::-1])\n",
    "IFrame('tmp/model.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import webbrowser\n",
    "web = webbrowser.get('google-chrome')\n",
    "web.open_new_tab('tmp/model.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from theano_models import Subgraph\n",
    "next(m for m in Subgraph.all_subgraphs if \"variational\" in m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"500\"\n",
       "            src=\"tmp/loss.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdb4bcb75d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], optimizer_kwargs['loss'], mode=\"FAST_COMPILE\", profile=True)\n",
    "f = [model['flat']] + model['inputs'], optimizer_kwargs['loss']\n",
    "d3viz(f, 'tmp/loss.html')\n",
    "IFrame('tmp/loss.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_train, = plot([], [], 'go-', label=\"average training loss\")\n",
    "line_curr_val, = plot([],[], 'bo:', label=\"avrg current validation loss\")\n",
    "line_best_val, = plot([], [], 'ko-', label=\"avrg best validation loss\")\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "yscale('log')\n",
    "ylabel(\"validation loss\")\n",
    "xlabel(\"#iteration\")\n",
    "legend(loc='lower left', fancybox=True, framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = inf\n",
    "best_wrt = None\n",
    "val_size = batch_size\n",
    "\n",
    "n_whole_data = X.shape[0] // batch_size\n",
    "\n",
    "for info in every(n_whole_data, opt):\n",
    "    # collect and visualize validation loss for choosing the best model\n",
    "    val_loss = optimizer_kwargs['num_loss'](opt.wrt, VZ[:val_size], VX[:val_size])/val_size\n",
    "    if val_loss < best_val_loss:\n",
    "        best_wrt = opt.wrt\n",
    "        best_val_loss = val_loss\n",
    "        add_point(line_best_val, info['n_iter'], val_loss)\n",
    "    add_point(line_curr_val, info['n_iter'], val_loss)\n",
    "    \n",
    "    # visualize training loss for comparison:\n",
    "    try:\n",
    "        training_loss = info['loss'] / len(Z)  # TODO normalization needed?\n",
    "    except KeyError:\n",
    "        training_loss = optimizer_kwargs['num_loss'](opt.wrt, Z, X)/len(Z)\n",
    "    add_point(line_train, info['n_iter'], training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: average over predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_val_loss\n",
    "mlp['parameters_flat'] = best_wrt\n",
    "\n",
    "predict = mlp.function()\n",
    "predict(X[0]), Z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PX = np.apply_along_axis(predict, 1, X)\n",
    "PVX = np.apply_along_axis(predict, 1, VX)\n",
    "PTX = np.apply_along_axis(predict, 1, TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'incorrect samples train/val/test:  %i/%i/%i' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).sum(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).sum(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).sum())\n",
    "\n",
    "print 'error rate train/val/test:  %g/%g/%g' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).mean(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).mean(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
