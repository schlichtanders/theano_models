{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot, ylabel, xlabel, yscale, xscale, legend, subplots\n",
    "from theano import function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from climin.util import optimizer\n",
    "from itertools import repeat, cycle, islice, izip\n",
    "inf = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.data import one_hot\n",
    "from breze.learn.base import cast_array_to_local_type\n",
    "from schlichtanders.myfunctools import compose\n",
    "from schlichtanders.myoptimizers import batch\n",
    "from schlichtanders.mygenerators import eatN, chunk, chunk_gen, every\n",
    "from schlichtanders.myplot import add_val, add_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_models import (as_tensor_variable, total_size, clone, clone_all,\n",
    "                           Merge, FlatKey, Reparameterize, squareplus, squareplus_inv,\n",
    "                           InvertibleModel,\n",
    "                           inputting_references, outputting_references)\n",
    "from theano_models.visualization import d3viz\n",
    "from IPython.display import IFrame\n",
    "import theano_models.deterministic_models as dm\n",
    "import theano_models.probabilistic_models as pm\n",
    "import theano_models.postmaps as post\n",
    "from theano_models.composing import normalizing_flow, variational_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano.printing import debugprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flat',\n",
       " 'inputs',\n",
       " 'n_data',\n",
       " 'noise',\n",
       " 'parameters',\n",
       " 'parameters_positive',\n",
       " 'parameters_pvalues',\n",
       " 'to_be_randomized'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputting_references.update(['to_be_randomized'])\n",
    "inputting_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kl_prior', 'logP', 'loglikelihood', 'norm_det', 'outputs'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputting_references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 784),\n",
       " (50000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10),\n",
       " (10000, 784),\n",
       " (10000, 10)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = '../data/mnist.pkl.gz'\n",
    "# Load data.        a                                                                                           \n",
    "\n",
    "with gzip.open(datafile,'rb') as f:                                                                        \n",
    "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
    "\n",
    "X, Z = train_set                                                                                               \n",
    "VX, VZ = val_set\n",
    "TX, TZ = test_set\n",
    "\n",
    "Z = one_hot(Z, 10)\n",
    "VZ = one_hot(VZ, 10)\n",
    "TZ = one_hot(TZ, 10)\n",
    "\n",
    "image_dims = 28, 28\n",
    "\n",
    "X, Z, VX, VZ, TX, TZ = [cast_array_to_local_type(i) for i in (X, Z, VX,VZ, TX, TZ)]\n",
    "map(np.shape, [X, Z, VX, VZ, TX, TZ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data modelling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for continous supervised data:\n",
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[200]*2, hidden_transfers=[\"rectifier\"]*2)\n",
    "post.flatten_parameters(predictor)\n",
    "\n",
    "target_distribution = pm.DiagGaussianNoise(predictor)\n",
    "\n",
    "targets = Merge(target_distribution, inputs=predictor['inputs'], to_be_randomized=predictor['parameters_flat'])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mlp5 { 'inputs': [AffineNonlinear9.inputs.0],\n",
       "  'outputs': AffineNonlinear10.outputs,\n",
       "  'parameters': [weights9, bias9, weights10, bias10]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = dm.Mlp(output_size=10, output_transfer=\"softmax\", hidden_sizes=[300]*1, hidden_transfers=[\"rectifier\"]*1)\n",
    "# post.flatten_parameters(predictor)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical5 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters_pvalues': [AffineNonlinear10.outputs]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution = pm.Categorical(predictor)\n",
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical5 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters_pvalues': [AffineNonlinear10.outputs]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge13 { 'inputs': [AffineNonlinear9.inputs.0],\n",
       "  'logP': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_pvalues': [],\n",
       "  'to_be_randomized': \"weights9_copy:bias9_copy:weights10_copy:bias10_copy\"}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = Merge(target_distribution, predictor, FlatKey(predictor, flat_key=\"to_be_randomized\"))\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagGauss5 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f3924793590 for function at 0x7f39247bf8c0>,\n",
       "  'noise': [DiagGaussianNoise5.noise.0],\n",
       "  'outputs': DiagGaussianNoise5.outputs,\n",
       "  'parameters': [mean9],\n",
       "  'parameters_positive': [var9]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_base = pm.DiagGauss(output_size=total_size(targets['to_be_randomized']))  # if you want to use size directly, CAUTION, you need to copy before!\n",
    "# params_base.map('parameters_positive', reparameterize_map(squareplus, squareplus_inv), 'parameters')\n",
    "params_base"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "params_base.noise.shape.eval({targets['inputs'][0]:X[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PlanarTransform9 { 'inputs': [z9],\n",
       "   'norm_det': PlanarTransform9.norm_det,\n",
       "   'outputs': PlanarTransform9.outputs,\n",
       "   'parameters': [b9, w9, _u9]}, PlanarTransform10 { 'inputs': [z10],\n",
       "   'norm_det': PlanarTransform10.norm_det,\n",
       "   'outputs': PlanarTransform10.outputs,\n",
       "   'parameters': [b10, w10, _u10]}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normflows = [dm.PlanarTransform() for _ in range(2)]\n",
    "normflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_flow10 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f39247934b0 for function at 0x7f392474bde8>,\n",
       "  'noise': [DiagGaussianNoise5.noise.0],\n",
       "  'norm_det': PlanarTransform10.norm_det,\n",
       "  'outputs': PlanarTransform10.outputs,\n",
       "  'parameters': [b10, w10, _u10, b9, w9, _u9, mean9],\n",
       "  'parameters_positive': [var9]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = params_base\n",
    "for transform in normflows:\n",
    "    params = normalizing_flow(transform, params)  # returns transform, however with adapted logP    \n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gauss5 { 'inputs': [],\n",
       "  'logP': <FunctionWrapper at 0x7f3924793600 for function at 0x7f39246f8848>,\n",
       "  'noise': [GaussianNoise5.noise.0],\n",
       "  'outputs': GaussianNoise5.outputs,\n",
       "  'parameters_positive': [var10]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = pm.Gauss(total_size(targets['to_be_randomized']))\n",
    "del prior['parameters']  # mean is not adapted at all, but left centred at zero\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variational_lower_bound5 { 'inputs': [AffineNonlinear9.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f39247937c0 for function at 0x7f392471a848>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [DiagGaussianNoise5.noise.0, GaussianNoise5.noise.0],\n",
       "  'norm_det': PlanarTransform10.norm_det,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters': [b10, w10, _u10, b9, w9, _u9, mean9],\n",
       "  'parameters_positive': [var9, var10],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = variational_bayes(targets, 'to_be_randomized', params, priors=prior, merge_priors=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge14 { 'inputs': [AffineNonlinear9.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f39247937c0 for function at 0x7f392471a848>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [DiagGaussianNoise5.noise.0, GaussianNoise5.noise.0],\n",
       "  'norm_det': PlanarTransform10.norm_det,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters': [ b10,\n",
       "                  w10,\n",
       "                  _u10,\n",
       "                  b9,\n",
       "                  w9,\n",
       "                  _u9,\n",
       "                  mean9,\n",
       "                  var9_squareplus,\n",
       "                  var10_squareplus],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model, Reparameterize(model['parameters_positive'], squareplus, squareplus_inv))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merge15 { 'flat': \"b10_copy:w10_copy:_u10_copy:b9_copy:w9_copy:_u9_copy:mean9_copy:var9_squareplus_copy:var10_squareplus_copy\",\n",
       "  'inputs': [AffineNonlinear9.inputs.0],\n",
       "  'kl_prior': kl_prior,\n",
       "  'logP': <FunctionWrapper at 0x7f39247937c0 for function at 0x7f392471a848>,\n",
       "  'loglikelihood': <FunctionWrapper at 0x7f3924a16f30 for function at 0x7f39247c9410>,\n",
       "  'n_data': n_data,\n",
       "  'noise': [],\n",
       "  'noise_flat': \"DiagGaussianNoise5.noise.0_copy:GaussianNoise5.noise.0_copy\",\n",
       "  'norm_det': PlanarTransform10.norm_det,\n",
       "  'outputs': Categorical5.outputs,\n",
       "  'parameters': [],\n",
       "  'parameters_positive': [],\n",
       "  'parameters_pvalues': []}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Merge(model,\n",
    "              FlatKey(model),\n",
    "              FlatKey(model, key=\"noise\", flat_key=\"noise_flat\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "model = Merge(model,\n",
    "              FlatKey(model, initial_inputs=[X[0]]),\n",
    "              FlatKey(model, key=\"noise\", flat_key=\"noise_flat\", initial_inputs=[X[0]]))\n",
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model['noise_flat'].shape.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InvertibleModel.reduce_all_identities()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "InvertibleModel.INVERTIBLE_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': <function schlichtanders.myoptimizers.f_batch>,\n",
       " 'fprime': <function schlichtanders.myoptimizers.f_batch>,\n",
       " 'wrt': array([-0.00108581,  1.01182628,  0.99703656, ...,  0.99346847,\n",
       "         1.00343572,  0.99808337])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postmap = compose(post.flat_numericalize_postmap, post.variational_postmap)\n",
    "postmap_kwargs = {\n",
    "    'wrapper': batch,\n",
    "    'initial_inputs': [X[0]],\n",
    "    'adapt_init_params': lambda ps: ps + np.random.normal(size=ps.size) * 0.01,\n",
    "    'profile': True,\n",
    "    'mode': 'FAST_RUN'\n",
    "}\n",
    "optimizer_kwargs = postmap(model, **postmap_kwargs)\n",
    "climin_kwargs = post.climin_postmap(optimizer_kwargs)\n",
    "climin_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climin wants an iterator of (args, kwarsg) as keyword argument \"args\" (to be passed to the loss function). Concretley, we use an infinite iterator over minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO write chunk with O(M) M=number of minibatches\n",
    "the current implementation is O(N) N=number of samples, because of use of generators instead of list slicing\n",
    "\n",
    "try to use ``chunk_gen``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "climin_args = izip(izip(chunk(batch_size, cycle(Z)), chunk(batch_size, cycle(X))), repeat({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = optimizer(\n",
    "    identifier = \"adadelta\",\n",
    "    args=climin_args, # repeat(((Z,X),{})),\n",
    "    **climin_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f = theano.function([model['flat']] + model['inputs'], model['outputs'], mode=\"FAST_COMPILE\")\n",
    "f = [model['flat']] + model['inputs'], model['outputs']\n",
    "d3viz(f, 'tmp/model.html', match_by_names=True) #, [targets, target_distribution, predictor, params] + predictor.layers + normflows + [params_base] + Helper.all_helpers[::-1])\n",
    "IFrame('tmp/model.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import webbrowser\n",
    "web = webbrowser.get('google-chrome')\n",
    "web.open_new_tab('tmp/model.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer_kwargs['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer_kwargs['num_loss'](optimizer_kwargs['num_parameters'], Z[0:1], X[0:1])\n",
    "\n",
    "f = optimizer_kwargs['num_loss'].wrapped\n",
    "d3viz(f, 'tmp/loss.html', match_by_names=True)\n",
    "IFrame('tmp/loss.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer_kwargs['num_jacobian'](optimizer_kwargs['num_parameters'], Z[0:100], X[0:100])\n",
    "\n",
    "f = optimizer_kwargs['num_jacobian'].wrapped\n",
    "d3viz(f, 'tmp/gradient.html', match_by_names=True)\n",
    "IFrame('tmp/gradient.html', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_train, = plot([], [], 'go-', label=\"average training loss\")\n",
    "line_curr_val, = plot([],[], 'bo:', label=\"avrg current validation loss\")\n",
    "line_best_val, = plot([], [], 'ko-', label=\"avrg best validation loss\")\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "yscale('log')\n",
    "ylabel(\"validation loss\")\n",
    "xlabel(\"#iteration\")\n",
    "legend(loc='lower left', fancybox=True, framealpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = inf\n",
    "best_wrt = None\n",
    "val_size = batch_size\n",
    "\n",
    "n_whole_data = X.shape[0] // batch_size\n",
    "\n",
    "for info in every(n_whole_data, opt):\n",
    "    # collect and visualize validation loss for choosing the best model\n",
    "    val_loss = optimizer_kwargs['num_loss'](opt.wrt, VZ[:val_size], VX[:val_size])/val_size\n",
    "    if val_loss < best_val_loss:\n",
    "        best_wrt = opt.wrt\n",
    "        best_val_loss = val_loss\n",
    "        add_point(line_best_val, info['n_iter'], val_loss)\n",
    "    add_point(line_curr_val, info['n_iter'], val_loss)\n",
    "    \n",
    "    # visualize training loss for comparison:\n",
    "    try:\n",
    "        training_loss = info['loss'] / len(Z)  # TODO normalization needed?\n",
    "    except KeyError:\n",
    "        training_loss = optimizer_kwargs['num_loss'](opt.wrt, Z, X)/len(Z)\n",
    "    add_point(line_train, info['n_iter'], training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: average over predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_val_loss\n",
    "mlp['parameters_flat'] = best_wrt\n",
    "\n",
    "predict = mlp.function()\n",
    "predict(X[0]), Z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PX = np.apply_along_axis(predict, 1, X)\n",
    "PVX = np.apply_along_axis(predict, 1, VX)\n",
    "PTX = np.apply_along_axis(predict, 1, TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'incorrect samples train/val/test:  %i/%i/%i' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).sum(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).sum(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).sum())\n",
    "\n",
    "print 'error rate train/val/test:  %g/%g/%g' % (\n",
    "    (PX[:, :10].argmax(1) != Z.argmax(1)).mean(),\n",
    "    (PVX[:, :10].argmax(1) != VZ.argmax(1)).mean(),\n",
    "    (PTX[:, :10].argmax(1) != TZ.argmax(1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
